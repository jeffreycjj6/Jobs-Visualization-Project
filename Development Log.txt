First started wtih creating the actual web applciation through Python's flask library
Then had to register the webpages that would be generated from that and supply their html renders
The first renders were of the data obtained from the kaggle cleaning
Then added an SVG map of the USA and used CSS styling to make it interactable for every single state
    Ran into a few problems involving being able to hover and highlight borders
Next is to generate a page for each individual state that will showcase its aggregate data and all of its job listings
    This can be done by making variable parameters for the state html that displays a dataset of only the <<state>> in question
    Images could be done in a similar way
    Hopefully will also be able to map out each individual location of a job based on its city in that state
    Basically write code that will generate state.html rather than create a unique page for all states individually
Finally make the site more pretty by adding effects and designs


Development Log - Jeff C.

5/8/2023
- Set up the inital wep app for the application such as the URLs and basic routes
- Added html pages for the dataframes, the main map homepage and started dynamic state pages
    - Added the SVG Map of the United States and enabled each state to be hover-able
    - Converted the clean dataframes to CSV's and then to HTML's

5/10/2023
- Continued dynamic html pages for all 50 states, though currently only Alabama, Arizona and Alaska are directly accessible
    - Each page showcases aggregate data in 1-line sentences and then shows a table of all job listings for that state
        - This is done by passing in state-specific versions of the main aggregate/listing dataframe csv's
        - For the main job listings, an html was passed in instead to take advantage of Pandas to_html function
    - Dynamic imaging was set up using the URL parameters, though only Alabama has an actual image as of now
    - CSS was adjusted to make all of the new data shown to be aligned with the center
- Did some additional data cleaning for the datasets to include most common job title and city location for the aggregate data (and included its singular version for job dataframe)
    - This also includes adding a standardized average and median salary for the aggregate data
    - Finally did some cleaning up on numbers to reduce them to 2 decimal places maximum
- To-Do:
    - Add images for all 50 states which can either be generic state images or possibly GEOPANDAS generated city/job-plotted state images
    - Clean up data dispaly by organizing the layout of it
        - Furthermore, find a method of better showcasing what types of jobs are found most often in that state
    - Add a style for all webpages to make it look prettier
        - This can possibly include also changing fonts and colors
    - Possibly add a search bar that detects/provides a list of all the jobs you are looking for and from what state (could add ML to this)
    - POssibly figure out a way to plot an interactive map for all job listings (though a static GEOPANDAS image would suffice)

5/12/2023
- Fixed major issues in dataframe analysis
    - Washington DC was being counted in the aggregate data but wasn't supposed to be, causing much of the data to be off by one row
        - Removed Washington DC from all dataframe analysis
    - Additionally, the order of the states did not coincide with some of the calculations as the original dictionary used was alphabetized on state abbreviations instead of names
        - This was fixed and reordered to allow things such as capital cooordinates from external CSV's to match identically with the aggregate data
- Added coordinates to all cities found in the main dataframe and the capital cities of the aggregate data
    - This was done by applying a dictionary of coordinates for each city for the regular job entires
    - While an external CSV of capital city coordinates was used for aggregate
- Began framework for Choropleth plotting with that data

5/14/2023
- Added actual heat maps for each state
    - This is done using Python's folium
        - Heatmaps are generated in a 3 step process:
            - First a dataframe of each city with the number of jobs it holds is created
            - Then, a coordinate pair (latitude, longitude) is mapped to those cities
            - Using the folium heatmap function, an interactive map is generated showing where those jobs are most concentrated
        - This heatmap is then saved into an html file and displayed dynamically through the state.html page
- Completed additional data cleanup where some coordinates were misplaced and off
- Added half finished credits page
- Began a more data page that will showcase the whole USA's heat map alongside a way to look at choropleth maps of specific jobs across the USA
    - This may be done with a search bar or text input that redirects to a page that displays a specific choropleth map
- Deleted unused files such as Alabama.jpg
- To-Do:
    - Add a general site design through CSS
        - Add a possible home page button for all HTML pages
    - Complete the "more data" page
    - Clean Up Data Analysis Code

5/15/2023
- Aded Choropleth Generator
    - Used HTML form input to look at specific job titles and generates a geopandas dataframe from that
    - Added an input that adjusts the map to be either percent based or count based
        - For count based choropleths, a scale factor was also created to have better visualization due to large job count differences
    - Saved as jpg files that dynamically update based on the inputted job
- Added Salary Choropleth
    - Done in data_analysis to create fixed salary maps using geopandas
    - Process is the same as Choropleth generator, take a column from aggregate data and map it to the us json file.
- Finalized state colors on homepage
    - Also added messages for states with no jobs like South Dakota or Alaska
- Finalized credits and sources page
- Fixed some formatting across some site pages

5/16/2023
- Fixed issue where heat maps were displayed starting at the city with the most Occurences
    - This happened due to a simple error in the code where the location was being assigned to the index 0 of the heat map dataframe
- Added code comments and cleaned up some parts of the code
- Adjusted credits
